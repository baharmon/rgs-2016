<section>
<h3 style="color: #888"><a href="http://www.isprs2016-prague.com/">Royal Geographical Society 2016</a></h3>
<h1 style="margin-top: 0.5em">Tangible Geographies</h1>
<h2 style="margin-top: 0.5em">Coupling physical and digital geographies</h2>
<h4>Brendan Harmon, Anna Petrasova, Vaclav Petras, Helena Mitasova, &amp; Ross Meentemeyer</h4>
<img height="100px" style="margin-top: 2em" src="img/logos/cgaBlack.png">
</section>

<!-- Pervasive data -->

  <!-- Internet of things & Smart cities -->

  <!-- 3D sensing -->

    <!-- Kinect -->

    <!-- UAVs -->

    <!-- Lidar -->

    <!-- Global scale -->

<!-- Digital fabrication -->

  <!-- 3D printing -->

  <!-- Robotic fabrication -->


    <!-- Flight assembled architecture: http://gramaziokohler.arch.ethz.ch/web/e/forschung/209.html -->
    <!-- <i class="fa fa-copyright" aria-hidden="true"></i> Gramazio Kohler Research, ETH Zurich -->

  <!-- Precision agriculture -->

  <!-- Autonomous construction -->

  <!-- Robotic construction -->

<!-- Tangible interfaces -->

  <!-- INFORM -->
  <section>
  <h2>inFORM</h2>
  <img height="500px" src="img/mit/inform.jpg">
  <p><a href="http://tangible.media.mit.edu/project/inform/">Tangible Media Group, MIT Media Lab</a></p>
  <p style="font-size:0.75em">Source: <i class="fa fa-creative-commons" aria-hidden="true"></i> <a href="http://tangible.media.mit.edu/project/inform/">Tangible Media Group, MIT Media Lab</a></p>
  <!--
  <p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/527-inFORM%20Dynamic%20Physical%20Affordances/Published/PDF">Follmer, Sean, Daniel Leithinger, Alex Olwal, Akimitsu Hogge, and H Ishii. 2013. “inFORM: Dynamic Physical Affordances and Constraints through Shape and Object Actuation.” In UIST ’13 Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology, 417–426. St. Andrews, UK: ACM Press. doi:10.1145/2501988.2502032. </a></p>
  -->
  </section>

  <!-- Augmented Reality Sandbox -->
  <section>
  <h2>Augmented Reality Sandbox</h2>
  <img height="500px" src="img/sarndbox/SARndbox_1.jpg">
  <p><a href="https://arsandbox.ucdavis.edu/">UC Davis</a></p>
  <p style="font-size:0.75em">Source: <i class="fa fa-copyright" aria-hidden="true"></i> <a href="http://idav.ucdavis.edu/~okreylos/ResDev/SARndbox/index.html">Oliver Kreylos</a></p>
  </section>

  <section>
  <h2>Augmented Reality Sandbox</h2>
  <iframe width="750" height="422" src="https://www.youtube.com/embed/CE1B7tdGCw0" frameborder="0" allowfullscreen></iframe>
  <p>Source: <a href="https://arsandbox.ucdavis.edu/">UC Davis</a></p>
  </section>

  <!-- Illuminating Clay -->
  <section>
  <h2>Illuminating Clay</h2>
  <img style="margin-top: 1em" height="500px" src="img/mit/illuminating_clay.png">
  <p><a href="http://tangible.media.mit.edu/project/illuminating-clay/">Tangible Media Group, MIT Media Lab</a></p>
  <p style="font-size:0.75em">Source: <i class="fa fa-copyright" aria-hidden="true"></i> <a href="http://tangible.media.mit.edu/project/illuminating-clay/">Tangible Media Group, MIT Media Lab</a></p>
  <p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
  </section>

  <!-- Tangible Geospatial Modeling System -->

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible user interface powered by open source GIS</h3>
<img height="150px" src="img/logos/logo_black.png">
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_videos/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/mit/illuminating_clay.png">
<img height="250px" src="img/tl_images/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/tl_diagrams/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Features -->
<section>
<h2>Features</h2>
<video  data-autoplay width="90%" style="margin-top: 0.5em" controls>
<source src="img/tl_videos/tl_immersion.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>A collaborative environment for tangible freeform modeling, object detection, real-time geospatial analytics, 3D rendering, and immersion / VR</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling with Tangible Landscape</h2>
<img width="25%" src="img/tl_images/subsurface_1.jpg">
<img width="25%" src="img/tl_images/subsurface_2.jpg">
<img width="40.55%" src="img/tl_images/subsurface_3.jpg">
<p>Tangible Landscape is designed to enable a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- TL + robotic fabrication -->
<section>
<h2>Tangible Landscape with virtual reality</h2>
<img style="margin-top: 1em" height="500px" src="img/tl_diagrams/system_schema_vr_blender.png">
<p>Real-time 3D rendering and immersive visualization for Tangible Landscape</p>
</section>

<!-- TL + robotic fabrication -->
<section>
<h2>Tangible Landscape with robotic fabrication</h2>
<img style="margin-top: 1em" height="500px" src="img/tl_diagrams/system_schema_robot.png">
<p>In-situ robotic fabrication for Tangible Landscape</p>
</section>

<!-- TL + robotic fabrication + streaming data + autonomous construction -->
<section>
<h2>Tangible Landscape with robotic fabrication, streaming data, and autonomous construction</h2>
<img style="margin-top: 1em" width="90%" src="img/tl_diagrams/system_schema_land.png">
<p>Bi-directionally coupling physical and digital landscapes</p>
</section>

<!-- Example -->


<!-- Example -->


<!-- Book -->
<section>
<h2>Build your own</h2>
<img width="20%" src="img/tl_images/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a>
or visit our website at <a href="http://tangible-landscape.github.io/">http://tangible-landscape.github.io/</a>
and give it a try.</p>
</section>

<!-- Build your own -->
